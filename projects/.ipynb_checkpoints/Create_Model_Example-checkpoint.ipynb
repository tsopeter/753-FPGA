{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7876334c-9228-427b-a92d-61af5c2e2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import onnx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from   brevitas.nn import QuantConv2d, QuantLinear, QuantReLU\n",
    "from   brevitas.export import export_qonnx\n",
    "from   qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from   qonnx.core.modelwrapper import ModelWrapper\n",
    "from   qonnx.core.datatype import DataType\n",
    "from   finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "664201fa-0a9f-4f3c-a99c-8cee61e5744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.environ['FINN_ROOT'] + '/notebooks/projects/'\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d32c380-ab47-41a4-92c8-7ee75ee1511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PilotNet model\n",
    "class PilotNet(nn.Module):\n",
    "    def __init__(self, width : int = 320, height : int = 240,\n",
    "                weight_bit_width : int = 4, act_bit_width : int = 4, width_multiplier : float = 1.0,\n",
    "                convz : int = 5, densez : str = 3):\n",
    "        super(PilotNet, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width  = width\n",
    "        self.width_multiplier  = width_multiplier\n",
    "\n",
    "        self.weight_bit_width = weight_bit_width\n",
    "        self.act_bit_width    = act_bit_width\n",
    "\n",
    "        self.conv1  = QuantConv2d(1,  int(24*self.width_multiplier), kernel_size=5, stride=2, weight_bit_width=self.weight_bit_width)\n",
    "        self.conv2  = QuantConv2d(int(24*self.width_multiplier), int(36*self.width_multiplier), kernel_size=5, stride=2, weight_bit_width=self.weight_bit_width)\n",
    "        self.conv3  = QuantConv2d(int(36*self.width_multiplier), int(48*self.width_multiplier), kernel_size=5, stride=2, weight_bit_width=self.weight_bit_width)\n",
    "        self.conv4  = QuantConv2d(int(48*self.width_multiplier), int(64*self.width_multiplier), kernel_size=3, stride=1, weight_bit_width=self.weight_bit_width)\n",
    "        self.conv5  = QuantConv2d(int(64*self.width_multiplier), int(64*self.width_multiplier), kernel_size=3, stride=1, weight_bit_width=self.weight_bit_width)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.cvz = nn.ModuleList()\n",
    "        for i in range(min(5, convz)):\n",
    "            if (i == 0):\n",
    "                self.cvz.append(self.conv1)\n",
    "            elif (i == 1):\n",
    "                self.cvz.append(self.conv2)\n",
    "            elif (i == 2):\n",
    "                self.cvz.append(self.conv3)\n",
    "            elif (i == 3):\n",
    "                self.cvz.append(self.conv4)\n",
    "            else:\n",
    "                self.cvz.append(self.conv5)\n",
    "\n",
    "        self.flattened_size = self._get_flattened_size()\n",
    "\n",
    "        self.relu1  = QuantReLU(bit_width=self.act_bit_width)\n",
    "\n",
    "        hidden_sizes = [100, 50, 10]\n",
    "\n",
    "        for i in range(len(hidden_sizes)):\n",
    "            hidden_sizes[i]=int(hidden_sizes[i]*self.width_multiplier)\n",
    "        \n",
    "        self.fcs = nn.ModuleList()\n",
    "        in_features = self.flattened_size\n",
    "\n",
    "        for i in range(min(densez, len(hidden_sizes))):\n",
    "            self.fcs.append(QuantLinear(in_features, hidden_sizes[i], bias=True, weight_bit_width=self.weight_bit_width))\n",
    "            in_features = hidden_sizes[i]\n",
    "            \n",
    "        self.output = QuantLinear(in_features, 1, bias=True, weight_bit_width=self.weight_bit_width)\n",
    "\n",
    "    def _get_flattened_size(self):\n",
    "        x = torch.zeros(1,1,self.height,self.width)\n",
    "        for cvz in self.cvz:\n",
    "            x = cvz(x)\n",
    "        x = self.flatten(x)\n",
    "        return x.shape[1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for cvz in self.cvz:\n",
    "            x = self.relu1(cvz(x))\n",
    "        x = self.flatten(x)\n",
    "        for fc in self.fcs:\n",
    "            x = self.relu1(fc(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def getDataset():\n",
    "    pass\n",
    "\n",
    "def train(model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4548bf5d-b8ff-4d05-b1f6-d6b790bfac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64,64)\n",
    "model = PilotNet(input_shape[0], input_shape[1], convz = 4, densez = 1, width_multiplier=0.4, weight_bit_width=4, act_bit_width=4)\n",
    "model.to(device)\n",
    "\n",
    "getDataset()\n",
    "\n",
    "# train the model\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4809bba8-77e6-422b-a4f5-b990caeb4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/petertso/finn/notebooks/projects//model.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/petertso/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ready_model_filename = model_dir + '/model.onnx'\n",
    "input_a = np.random.randint(0, 255, size=(1,1,input_shape[0], input_shape[1])).astype(np.float32)\n",
    "input_t = torch.from_numpy(input_a)\n",
    "\n",
    "model.cpu()\n",
    "export_qonnx(model, export_path=ready_model_filename, input_t=input_t)\n",
    "qonnx_cleanup(ready_model_filename, out_file=ready_model_filename)\n",
    "\n",
    "model = ModelWrapper(ready_model_filename)\n",
    "model.set_tensor_datatype(model.graph.input[0].name, DataType['UINT8'])\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(ready_model_filename)\n",
    "\n",
    "print(f'Model saved to {ready_model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4bb20-baf1-41c9-9650-2ffaff64c61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5f02d-cdb5-419b-a619-32065370b03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
